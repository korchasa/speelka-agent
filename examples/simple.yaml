# Sample YAML configuration for Speelka Agent
agent:
  name: "simple-speelka-agent"
  version: "1.0.0"

  # Tool configuration
  tool:
    name: "process"
    description: "Process tool for handling user queries with LLM"
    argument_name: "input"
    argument_description: "The user query to process"

  # LLM configuration
  llm:
    provider: "openai"
    api_key: ""  # Set via environment variable instead for security
    model: "gpt-4o"
    max_tokens: 0
    temperature: 0.7
    prompt_template: "You are a helpful AI assistant. Respond to the following request: {{input}}. Provide a detailed and helpful response. Available tools: {{tools}}"

    # Retry configuration for LLM
    retry:
      max_retries: 3
      initial_backoff: 1.0
      max_backoff: 30.0
      backoff_multiplier: 2.0

  # MCP Server connections
  connections:
    mcpServers:
      time:
        command: "docker"
        args: ["run", "-i", "--rm", "mcp/time"]
        environment: {}

      filesystem:
        command: "mcp-filesystem-server"
        args: ["/Users/korchasa/www/speelka/speelka-agent"]
        environment: {}

    # Retry configuration for MCP connections
    retry:
      max_retries: 3
      initial_backoff: 1.0
      max_backoff: 30.0
      backoff_multiplier: 2.0

  # Chat configuration
  chat:
    max_tokens: 0
    compaction_strategy: "delete-old"

# Runtime configuration
runtime:
  log:
    level: "debug"
    output: "./test.log"

  transports:
    stdio:
      enabled: true
      buffer_size: 8192

    http:
      enabled: false
      host: "localhost"
      port: 3000