# Remote Resources

## Protocols & Libraries
- [Model Context Protocol (MCP)](https://github.com/modelcontextprotocol/docs)
- [MCP-Go](https://github.com/mark3labs/mcp-go)
- [LangChainGo](https://github.com/tmc/langchaingo)
- [Logrus](https://github.com/sirupsen/logrus)
- [Koanf (core)](https://github.com/knadh/koanf)
  - [Official documentation](https://pkg.go.dev/github.com/knadh/koanf/v2)
  - [Providers: file, env, confmap, structs, posflag, basicflag, s3, etc.](https://github.com/knadh/koanf#providers)
  - [Parsers: json, yaml, toml, dotenv, hcl, hjson, nestedtext](https://github.com/knadh/koanf#parsers)
- [Tiktoken-go](https://github.com/pkoukk/tiktoken-go)

## LLM Providers
- [OpenAI API](https://platform.openai.com/docs/api-reference)
- [Anthropic API](https://docs.anthropic.com/claude/reference/getting-started-with-the-api)

## Tools & Utilities
- [MCP Inspector](https://www.npmjs.com/package/@modelcontextprotocol/inspector)
- [MCP Filesystem Server](https://github.com/mark3labs/mcp-filesystem-server)
- [MCP Playwright](https://github.com/executeautomation/mcp-playwright)

## Docker
- [speelka-agent Docker Image](https://github.com/korchasa/speelka-agent-go/pkgs/container/speelka-agent)

## LLM Token Counting
- Refer to official OpenAI and Anthropic documentation for token counting details.
- Project uses exact token counts from LLM responses by default, with fallback to a centralized estimation utility if needed.

# No references to deleted files or interfaces remain.

// All links verified as of 2025-04-15.